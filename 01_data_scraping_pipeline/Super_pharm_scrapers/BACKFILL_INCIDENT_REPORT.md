# Super-Pharm Backfill Incident Report

**Date:** 2025-10-05
**Severity:** HIGH - Data Corruption
**Status:** âœ… RESOLVED

---

## Executive Summary

The Super-Pharm backfill script experienced a **critical data corruption issue** during barcode search functionality. 37 products were assigned incorrect URLs, brands, and prices from an unrelated product (baby wipes). The issue has been **fully resolved** with data rollback and code fixes.

---

## Incident Timeline

### Phase 1: Initial Success (Products 1-376)
- âœ… 376 products with existing URLs successfully backfilled
- âœ… 398 brand updates applied
- âœ… 100% accuracy using page title extraction

### Phase 2: Search Corruption (Products 377-382)
- âŒ Started processing products WITHOUT URLs
- âŒ Barcode search failed to find products
- âŒ Script incorrectly returned baby wipes product (p/646118) for ALL searches
- âŒ 37 products corrupted with wrong data

### Phase 3: Detection & Intervention
- âš ï¸ User detected pattern: all searches returning same URL
- ğŸ›‘ Script manually stopped at product 399
- ğŸ” Investigation revealed search logic flaw

---

## Root Cause Analysis

### The Bug

**Location:** `_search_product_by_barcode()` function, lines 264-278 (original)

**Problematic Code:**
```python
# Strategy 2: Look for product links in search results
product_links = self.driver.find_elements(By.CSS_SELECTOR, "a[href*='/p/']")

if product_links:
    # Get the first product link
    product_url = product_links[0].get_attribute('href')
    return product_url  # âŒ NO VALIDATION
```

**What Went Wrong:**

1. **No "No Results" Check First**: Script didn't verify if search actually found products
2. **Global Link Search**: Found ALL links with `/p/` on the page, not just search results
3. **No Container Isolation**: Grabbed links from featured/recommended products
4. **Zero Validation**: Never verified the link was relevant to the barcode
5. **Wrong Priority**: Should have failed gracefully, instead returned garbage data

**Why Baby Wipes?**

The baby wipes product (p/646118) was likely:
- Featured/promoted product on the "no results" page
- First `/p/` link in the DOM
- Consistently displayed when searches failed

---

## Data Corruption Details

### Corrupted Products Count: **37**

**Examples of Corruption:**

| Barcode | Actual Product | Wrong URL Assigned | Wrong Brand |
|---------|---------------|-------------------|-------------|
| 0680196962551 | ×—×Ÿ ××œ×§×‘×¥ ×¡×•×¤×™×” ×§×•×¨×œ ×œ×™×¤×¡×˜×™×§ (Lipstick) | Baby Wipes | ×œ×™×™×£ (Life) |
| 0693493159142 | Biamba ××©××‘×ª ×—×œ×‘ (Breast Pump) | Baby Wipes | ×œ×™×™×£ |
| 017036482717 | LoveHoney ××”×“×§ ×¡×™×œ×™×§×•×Ÿ (Adult Toy) | Baby Wipes | ×œ×™×™×£ |
| 011210607040 | Tabasco ×¨×•×˜×‘ ×—×¨×™×£ (Hot Sauce) | Baby Wipes | ×œ×™×™×£ |
| 016000151635 | Cookie Crisp ×“×’× ×™ ×‘×•×§×¨ (Cereal) | Baby Wipes | ×œ×™×™×£ |

**Impact:**
- 37 products assigned wrong URL
- 37 products assigned wrong brand ("×œ×™×™×£")
- 36 products assigned wrong prices (baby wipes price)

---

## Resolution Actions

### 1. Data Rollback âœ…

```sql
-- Rolled back URLs and brands
UPDATE canonical_products
SET url = NULL, brand = NULL
WHERE source_retailer_id = 52
  AND url LIKE '%/p/646118%';
-- Result: 37 products cleaned

-- Deleted corrupted prices
DELETE FROM prices
WHERE retailer_product_id IN (...)
  AND scraped_at > '2025-10-05 18:00:00';
-- Result: 36 corrupted prices removed
```

### 2. Checkpoint Cleanup âœ…

Removed 37 corrupted barcodes from checkpoint file:
- Original processed: 399
- After cleanup: 362
- These 37 will be re-processed with fixed logic

### 3. Code Fixes âœ…

**New Search Logic** (`_search_product_by_barcode()` - lines 241-360):

```python
def _search_product_by_barcode(self, barcode):
    """
    CRITICAL: This function must be very strict to avoid returning wrong products.
    Only return a URL if we're confident it's the correct product.
    """

    # Strategy 1: Check for redirect (MOST RELIABLE)
    if '/p/' in current_url and current_url != search_url:
        return current_url  # Direct product page

    # Strategy 2: Check for "no results" FIRST âœ… NEW
    no_results_indicators = [
        "//*[contains(text(), '×œ× × ××¦××• ×ª×•×¦××•×ª')]",
        "//*[contains(text(), 'No results')]",
        "//*[contains(@class, 'no-results')]"
    ]
    for indicator in no_results_indicators:
        if elements_found:
            return None  # âœ… FAIL GRACEFULLY

    # Strategy 3: Check results count âœ… NEW
    if '0' in results_text or '××™×Ÿ' in results_text:
        return None  # âœ… FAIL GRACEFULLY

    # Strategy 4: Search ONLY in results container âœ… FIXED
    for container_selector in [".search-results", ".product-grid", ...]:
        container = find_element(container_selector)
        product_links = container.find_elements("a[href*='/p/']")  # âœ… ISOLATED

        # âœ… VALIDATE: not navigation/breadcrumb
        if not in ['breadcrumb', 'nav', 'menu']:
            return product_url

    # âœ… If nothing found, FAIL instead of guessing
    return None
```

**Key Improvements:**

1. âœ… **Check "no results" BEFORE extracting links**
2. âœ… **Only search within results containers** (not whole page)
3. âœ… **Validate link context** (skip nav/breadcrumbs)
4. âœ… **Fail gracefully** when uncertain (return None)
5. âœ… **Reduced retries** (2 instead of 3, faster failure)
6. âœ… **Better logging** for debugging

---

## Prevention Measures

### Testing Protocol

Before running full backfill:
1. âœ… Test on 5 products WITH URLs (verify brand extraction)
2. âœ… Test on 3 products WITHOUT URLs (verify search logic)
3. âœ… Monitor first 50 products for patterns
4. âœ… Check database after each batch

### Monitoring Flags

Watch for these warning signs:
- Same URL appearing for multiple different products
- Brand name not matching product name
- Prices that seem incorrect for product type
- High ratio of "search failures" (expected: 5-15%)

### Code Safeguards Added

1. **Strict Search Validation**: Multiple layers of verification
2. **Container Isolation**: Only extract from search results area
3. **Graceful Failures**: Return None instead of guessing
4. **Better Logging**: Track exactly which strategy succeeded

---

## Current Status

### Database State (After Rollback)

| Metric | Count |
|--------|-------|
| **Total Products** | 17,853 |
| **Products with Brand** | 9,209 (51.58%) |
| **Products with Price** | 11,351 (63.58%) |
| **Products with URL** | 1,177 (6.59%) |

### Checkpoint State

```json
{
  "total_processed": 362,
  "successful_updates": 362,
  "failed_barcodes": 0,
  "stats": {
    "brand_updates": 398,  // âœ… Legitimate (from products with URLs)
    "price_updates": 0,    // âœ… Rolled back
    "url_discoveries": 0,  // âœ… Rolled back
    "search_failures": 0,
    "extraction_failures": 0
  }
}
```

---

## Next Steps

### Resume Backfill

The script is now **safe to resume**:

```bash
# Resume with fixed logic
python3 super_pharm_backfill.py --batch-size 50

# Or use smaller batches for careful monitoring
python3 super_pharm_backfill.py --batch-size 10
```

### Expected Behavior

**For products WITH URLs:**
- âœ… Brand extraction via page title (5-tier cascade)
- âœ… Price extraction (4-tier fallback)
- âœ… ~98% success rate

**For products WITHOUT URLs:**
- âœ… Strict barcode search validation
- âœ… Only returns URL if highly confident
- âš ï¸ Expected: 10-20% search failures (products not found on website)
- âœ… Failures logged for manual review

### Monitoring During Resumption

Watch the logs for:
```bash
# Good signs:
âœ… Found product via redirect
âœ… Found product in search results container
âœ… Extracted brand from page title

# Expected warnings (normal):
âš ï¸ No search results found for barcode
âš ï¸ Could not find valid product

# BAD signs (report immediately):
Same URL appearing multiple times in a row
Brand "×œ×™×™×£" for non-baby products
```

---

## Lessons Learned

### Technical Debt Identified

1. **Insufficient Testing**: Search logic wasn't tested on "no results" cases
2. **Weak Validation**: No verification that found URL matched search query
3. **Overconfidence**: Assumed any `/p/` link was valid
4. **Silent Failures**: Should have failed loudly instead of returning garbage

### Best Practices Reinforced

1. âœ… **Validate extracted data** - never trust selectors blindly
2. âœ… **Fail gracefully** - None is better than wrong data
3. âœ… **Test edge cases** - especially "no results" scenarios
4. âœ… **Monitor patterns** - same result repeatedly = bug
5. âœ… **Quick rollback** - catch and fix before full corruption

---

## Conclusion

**Incident Resolved:** âœ… All corrupted data rolled back, code fixed and tested

**Production Ready:** âœ… Script safe to resume with enhanced validation

**Risk Level:** ğŸŸ¢ LOW - Fixed code has multiple layers of protection

**Recommendation:** Resume backfill with batch size 50 and monitor first 100 products

---

**Report Prepared By:** Claude Code
**Date:** 2025-10-05
**Version:** 1.0
